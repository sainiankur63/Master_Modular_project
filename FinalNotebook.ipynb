{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9RYyExip6h03xAQprzMUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainiankur63/Master_Modular_project/blob/main/FinalNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hzmrlspXdmem"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy pandas matplotlib seaborn opendatasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To show all columns' names on a large pandas dataframe\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "matplotlib.rcParams['figure.figsize'] = (8,4)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "WUaHc5k6dsD7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "dataset_url = 'https://www.kaggle.com/austinreese/craigslist-carstrucks-data'\n",
        "\n",
        "\n",
        "od.download(dataset_url)\n",
        "\n",
        "data_dir = './craigslist-carstrucks-data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W5jeiVNd4K-",
        "outputId": "8d44847a-6f8e-49fb-a0da-890f4cd8039c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./craigslist-carstrucks-data\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking 10 percent fraction of the dataset\n",
        "sample_frac = 0.9\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "def skip_row(row_idx):\n",
        "    if row_idx == 0:\n",
        "        return False\n",
        "    return random.random() > sample_frac\n",
        "\n",
        "random.seed(42)\n",
        "df = pd.read_csv(data_dir+\"/vehicles.csv\", skiprows=skip_row)"
      ],
      "metadata": {
        "id": "_KSosU0Id4vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().applymap(lambda x: f\"{x:0.3f}\")"
      ],
      "metadata": {
        "id": "KsKkjw9p16bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DROP FEATURES**"
      ],
      "metadata": {
        "id": "wtdrfDvBeDi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['id', 'url','region_url', 'VIN', 'image_url', 'description', 'county', 'state', 'lat', 'long', 'posting_date'],axis =1 , inplace = True)"
      ],
      "metadata": {
        "id": "fcdcwVw8d9yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().applymap(lambda x: f\"{x:0.3f}\")"
      ],
      "metadata": {
        "id": "6DdRcfeXlSEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OUTLIER REMOVAL - price**"
      ],
      "metadata": {
        "id": "DngZagk3kd3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Lets compute the Interquantile range to calculate the boundaries\n",
        "IQR=df.price.quantile(0.75)-df.price.quantile(0.25)\n",
        "\n",
        "#### Extreme outliers\n",
        "lower_lim_price = df['price'].quantile(0.25) - ( IQR * 1.5 )\n",
        "upper_lim_price = df['price'].quantile(0.75) +  ( IQR * 1.5 )\n",
        "\n",
        "print(\"Price value for LOWER bound: \",lower_lim_price)\n",
        "print(\"Price value for UPPER bound: \",upper_lim_price)"
      ],
      "metadata": {
        "id": "twvYXNHGfMKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking 500 dollars as min and 57364 dollars max value for price\n",
        "\n",
        "df = df[(df.price >=  480) & (df.price <= 57364)]"
      ],
      "metadata": {
        "id": "5FLgt5xJkwxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df[(df.price >=  480) & (df.price <= 56137)].price)"
      ],
      "metadata": {
        "id": "PV-AAYMymAdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OUTLIER REMOVAL - year**"
      ],
      "metadata": {
        "id": "B0YinwAx0Yiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Lets compute the Interquantile range to calculate the boundaries\n",
        "IQR=df.year.quantile(0.75)-df.year.quantile(0.25)\n",
        "\n",
        "#### Extreme outliers\n",
        "lower_lim_year = df['year'].quantile(0.25) - ( IQR * 1.5 )\n",
        "upper_lim_year = df['year'].quantile(0.75) +  ( IQR * 1.5 )\n",
        "\n",
        "print(\"Minimum Year value : \",lower_lim_year)\n",
        "print(\"Maximum Year value: \",upper_lim_year)"
      ],
      "metadata": {
        "id": "63Fa0tGfzqA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking year greater than 1994\n",
        "\n",
        "df = df[(df['year'] >=  1994)]"
      ],
      "metadata": {
        "id": "D2_v7cje0HtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df.year)"
      ],
      "metadata": {
        "id": "CTesJh5x30Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().applymap(lambda x: f\"{x:0.3f}\")"
      ],
      "metadata": {
        "id": "wdZFEycJ7tgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OUTLIER REMOVAL - odometer**"
      ],
      "metadata": {
        "id": "daJ8JVQe4qP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Lets compute the Interquantile range to calculate the boundaries\n",
        "IQR = df.odometer.quantile(0.75) - df.odometer.quantile(0.25)\n",
        "\n",
        "#### Extreme outliers\n",
        "lower_lim_odometer = df['odometer'].quantile(0.25) - ( IQR * 1.5 )\n",
        "upper_lim_odometer = df['odometer'].quantile(0.75) + ( IQR * 1.5 )\n",
        "\n",
        "print(\"Min odometer value : \",lower_lim_odometer)\n",
        "print(\"Max odometer value: \",upper_lim_odometer)"
      ],
      "metadata": {
        "id": "-RuZsHUj4it0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set 200 miles as the lower limit and 284751 miles Upper limit \n",
        "df = df[(df.odometer >=  200) & (df.odometer <= 284751)]"
      ],
      "metadata": {
        "id": "RtJl2zEW5_ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df.odometer)"
      ],
      "metadata": {
        "id": "IhQFZ2xs-p6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        " \n",
        "plt.subplot(1,2,1) \n",
        "# Removing the missing percentages greater than zero.\n",
        "missing_percentages =df.isna().sum().sort_values(ascending=False)/len(df) \n",
        "# Plot a graph to check missing percentages \n",
        "missing_percentages[missing_percentages!=0].plot(kind='barh')\n",
        "plt.title(\"Graph for NULL data in percentage \")\n",
        "plt.xlabel(\"% of missing values\")\n",
        "plt.ylabel(\"Features\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "# creating a graph to check null values\n",
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n",
        "plt.title(\"Graph for NULL data \")"
      ],
      "metadata": {
        "id": "bC7oOaNa2lAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Null_Values = df.isna().sum()\n",
        "percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "missing_value_df = pd.DataFrame({'Null_Values' : Null_Values,'percent_missing': percent_missing})\n",
        "missing_value_df.sort_values(['percent_missing'],ascending=False)"
      ],
      "metadata": {
        "id": "rhyv0_F6I0bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Handling Missing and Null Values** \n"
      ],
      "metadata": {
        "id": "pb-4PYizm7CP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transmission**"
      ],
      "metadata": {
        "id": "gEeV3K-1nM47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in transmission :\" ,df['transmission'].isnull().sum())"
      ],
      "metadata": {
        "id": "LwdgvYf5m6fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in transmission column\n",
        "\n",
        "df['transmission'] = df['transmission'].fillna(df.transmission.mode()[0])"
      ],
      "metadata": {
        "id": "fiF7AoUdJ0ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values After handling in transmission :\" ,df['transmission'].isnull().sum())"
      ],
      "metadata": {
        "id": "xhtwPfXvnoth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fuel**"
      ],
      "metadata": {
        "id": "HY8jsE-OphFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in fuel :\" ,df['fuel'].isnull().sum())"
      ],
      "metadata": {
        "id": "NvQOCDugnxqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in fuel column\n",
        "\n",
        "df['fuel'] = df['fuel'].fillna(df.fuel.mode()[0])"
      ],
      "metadata": {
        "id": "GL7m2_6upr0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in fuel :\" ,df['fuel'].isnull().sum())"
      ],
      "metadata": {
        "id": "_sSDWMrIpyif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "hxAmK_Xhqp6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in model :\" ,df['model'].isnull().sum())"
      ],
      "metadata": {
        "id": "4165A7KZqqND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in model column\n",
        "\n",
        "df['model'] = df['model'].fillna(df.title_status.mode()[0])"
      ],
      "metadata": {
        "id": "ohsk1eXWp1fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in model :\" ,df['model'].isnull().sum())"
      ],
      "metadata": {
        "id": "j13rou-zq7uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Title_status**"
      ],
      "metadata": {
        "id": "w4u8OKWKrlO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in title_status :\" ,df['title_status'].isnull().sum())"
      ],
      "metadata": {
        "id": "AoulBEu3q9ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in title_status column\n",
        "\n",
        "df['title_status'] = df['title_status'].fillna(df.title_status.mode()[0])"
      ],
      "metadata": {
        "id": "6VTJwwLCtMTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in title_status :\" ,df['title_status'].isnull().sum())"
      ],
      "metadata": {
        "id": "iiecXcDGtMiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manufacturer**"
      ],
      "metadata": {
        "id": "BUWo8b9Wtj1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in manufacturer :\" ,df['manufacturer'].isnull().sum())"
      ],
      "metadata": {
        "id": "EM5M-X5OtWCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in manufacturer column\n",
        "\n",
        "df['manufacturer'] = df['manufacturer'].fillna(df.manufacturer.mode()[0])"
      ],
      "metadata": {
        "id": "Xs-07JoMt-G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in manufacturer :\" ,df['manufacturer'].isnull().sum())"
      ],
      "metadata": {
        "id": "QAyjtmy4uG0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type**"
      ],
      "metadata": {
        "id": "hs6YJ95AvKBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in type :\" ,df['type'].isnull().sum())"
      ],
      "metadata": {
        "id": "Zkj9lyQouJLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in type column\n",
        "\n",
        "df['type'] = df['type'].fillna(df.type.mode()[0])"
      ],
      "metadata": {
        "id": "hf64BhccvQs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in type :\" ,df['type'].isnull().sum())"
      ],
      "metadata": {
        "id": "O5IpOOHJvgWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paint_color**"
      ],
      "metadata": {
        "id": "S3PP5IjDwVu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in paint_color :\" ,df['paint_color'].isnull().sum())"
      ],
      "metadata": {
        "id": "ueIvIgsqvnTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in paint_color column\n",
        "\n",
        "df['paint_color'] = df['paint_color'].fillna(df.paint_color.mode()[0])"
      ],
      "metadata": {
        "id": "T5flnPWewcmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in paint_color :\" ,df['paint_color'].isnull().sum())"
      ],
      "metadata": {
        "id": "qWWkhH2RwhmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drive**"
      ],
      "metadata": {
        "id": "74JZaeumw9cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in drive :\" ,df['drive'].isnull().sum())"
      ],
      "metadata": {
        "id": "YKafS-Dwwlze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in drive column\n",
        "\n",
        "df['drive'] = df['drive'].fillna(df.drive.mode()[0])"
      ],
      "metadata": {
        "id": "eboNc7g8xCpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in drive :\" ,df['drive'].isnull().sum())"
      ],
      "metadata": {
        "id": "z99m8SwJxHNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Condition**"
      ],
      "metadata": {
        "id": "U7RZanMGx5eK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in condition :\" ,df['condition'].isnull().sum())"
      ],
      "metadata": {
        "id": "jHfQMVEcxKQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in condition column\n",
        "\n",
        "df['condition'] = df['condition'].fillna(df.condition.mode()[0])"
      ],
      "metadata": {
        "id": "vwy1zFi7yADu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in condition :\" ,df['condition'].isnull().sum())"
      ],
      "metadata": {
        "id": "1O1ujEWDyI9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cylinders**"
      ],
      "metadata": {
        "id": "NtmuYbvAylEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in cylinders :\" ,df['cylinders'].isnull().sum())"
      ],
      "metadata": {
        "id": "Y4a63qbByMU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in cylinders column\n",
        "\n",
        "df['cylinders'] = df['cylinders'].fillna(df.cylinders.mode()[0])"
      ],
      "metadata": {
        "id": "9j0vcUldyq0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in cylinders :\" ,df['cylinders'].isnull().sum())"
      ],
      "metadata": {
        "id": "gJBTNEnmy5xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Size**"
      ],
      "metadata": {
        "id": "rN1LIgYpzTCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values before handling in size :\" ,df['size'].isnull().sum())"
      ],
      "metadata": {
        "id": "gZNBZ9vNy8Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values in size column\n",
        "\n",
        "df['size'] = df['size'].fillna(df['size'].mode()[0])"
      ],
      "metadata": {
        "id": "RjVo22nzzqfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values after handling in size :\" ,df['size'].isnull().sum())"
      ],
      "metadata": {
        "id": "o1OEQKfGzzOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking null values again\n",
        "Null_Values = df.isna().sum()\n",
        "percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "missing_value_df = pd.DataFrame({'Null_Values' : Null_Values,'percent_missing': percent_missing})\n",
        "missing_value_df.sort_values(['percent_missing'],ascending=False)"
      ],
      "metadata": {
        "id": "MyQdl3nvz5gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "aNjUrOkT0V_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.cylinders.value_counts()"
      ],
      "metadata": {
        "id": "dLjzV78lAGzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding categorical variables**"
      ],
      "metadata": {
        "id": "zuDJIv76AYvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing label encoder from sklearn module\n",
        "\n",
        "from sklearn import preprocessing\n",
        "LabelEncoding = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "XHLDsxWtAQ7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting categorical columns from the DataFrame df\n",
        "categorical_columns = [i for i in df.columns if df.dtypes[i]=='object']"
      ],
      "metadata": {
        "id": "fetFC1N5Al-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for converting all categorical data to numbeic using label encoding \n",
        "for i in categorical_columns:\n",
        "  df[i] = LabelEncoding.fit_transform(df[i])"
      ],
      "metadata": {
        "id": "ftvBRL0lBBTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "oyMwN59jBmJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.drop(['index'],axis =1,inplace= True)"
      ],
      "metadata": {
        "id": "2D8HaWB3Bo3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "OyUjVdS8C59E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Independent variable \n",
        "X_data = df.drop('price',axis =1 )\n",
        "\n",
        "# dependent variable \n",
        "y_data = df['price']"
      ],
      "metadata": {
        "id": "wVt2nQ9wIwzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train-Test Split**"
      ],
      "metadata": {
        "id": "B4kzIaJuLmMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing train test split from sklearm\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Ey0zGcfpLjU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Shape of X_train: \",X_train.shape) \n",
        "print (\"Shape of y_train: \",y_train.shape)\n",
        "print (\"Shape of X_test: \",X_test.shape)\n",
        "print (\"Shape of y_test: \", y_test.shape)"
      ],
      "metadata": {
        "id": "bE8ZlrGVL4MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train= sc.fit_transform(X_train)\n",
        "X_test= sc.transform(X_test)"
      ],
      "metadata": {
        "id": "6xTNyjqFMVuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()   \n",
        "X_train= sc.fit_transform(X_train)\n",
        "X_test= sc.transform(X_test)"
      ],
      "metadata": {
        "id": "OmJyfzONM8P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import xgboost\n",
        "# from sklearn.metrics import mean_squared_error as MSE\n",
        "# from sklearn import metrics\n",
        "# import numpy as np"
      ],
      "metadata": {
        "id": "FZ3Bj7cNM-Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from xgboost import XGBRegressor\n",
        "# model = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
        "\n",
        "# model.fit(X_train, y_train)\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# print('Model Score:',model.score(X_test,y_test))\n",
        "# print('Mean Absolute Error:', round(metrics.mean_absolute_error(y_test, y_pred),2))\n",
        "# print('Mean Squared Error:', round(metrics.mean_squared_error(y_test, y_pred),2))\n",
        "# print('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),2))"
      ],
      "metadata": {
        "id": "_yJUmg7YNDP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from sklearn.tree import DecisionTreeRegressor \n",
        "# dec_regressor = DecisionTreeRegressor(random_state = 0) \n",
        "# dec_regressor.fit(X_train, y_train)\n",
        "\n",
        "# print('Model Score:',dec_regressor.score(X_test,y_test))\n",
        "# print('Mean Absolute Error:', round(metrics.mean_absolute_error(y_test, y_pred),2))\n",
        "# print('Mean Squared Error:', round(metrics.mean_squared_error(y_test, y_pred),2))\n",
        "# print('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),2))"
      ],
      "metadata": {
        "id": "4Yd4FlMdNFkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn import metrics\n",
        "# from sklearn.metrics import mean_squared_error as MSE\n",
        "# import numpy as np\n",
        "\n",
        "# n_est = [10,100]\n",
        "# for i in n_est:\n",
        "#   regressor = RandomForestRegressor(n_estimators=i, random_state=42)\n",
        "#   regressor.fit(X_train, y_train)\n",
        "#   y_pred = regressor.predict(X_test)\n",
        "#   print('n_estimators:',i)\n",
        "#   print('Model Score:',regressor.score(X_test,y_test))\n",
        "#   print('Mean Absolute Error:', round(metrics.mean_absolute_error(y_test, y_pred),2))\n",
        "#   print('Mean Squared Error:', round(metrics.mean_squared_error(y_test, y_pred),2))\n",
        "#   print('Root Mean Squared Error:' , round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),2))"
      ],
      "metadata": {
        "id": "kihUGNHNNTr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECISION TREE REGRESSOR**"
      ],
      "metadata": {
        "id": "PimqybSHHx4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing decision tree regressor from tree module\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "\n",
        "# Create a decision tree regressor\n",
        "decision_regressor = DecisionTreeRegressor(random_state = 0) \n",
        "\n",
        "# Train the model using the training sets\n",
        "decision_regressor.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "lUVOZi1-Nm1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "y_pred = decision_regressor.predict(X_test)\n",
        "\n",
        "print('Model Score:',round(r2_score(y_test, y_pred),3))\n",
        "print('Mean Absolute Error:', round(mean_absolute_error(y_test, y_pred),2))\n",
        "print('Mean Squared Error:', round(mean_squared_error(y_test, y_pred),2))\n",
        "print('Root Mean Squared Error:' , round(np.sqrt(mean_squared_error(y_test, y_pred)),2))"
      ],
      "metadata": {
        "id": "6v8jPXDGJMFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM FOREST REGRESSOR**"
      ],
      "metadata": {
        "id": "LUvYFi3cHxGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing Random Forest regressor from ensemble module\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create a Random Forest regressor\n",
        "RandomForest_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model using the training sets\n",
        "RandomForest_regressor.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Ti5aJ-eSMBOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "y_pred = RandomForest_regressor.predict(X_test)\n",
        "\n",
        "print('Model Score:',round(r2_score(y_test, y_pred),3))\n",
        "print('Mean Absolute Error:', round(mean_absolute_error(y_test, y_pred),3))\n",
        "print('Mean Squared Error:', round(mean_squared_error(y_test, y_pred),2))\n",
        "print('Root Mean Squared Error:' , round(np.sqrt(mean_squared_error(y_test, y_pred)),2))"
      ],
      "metadata": {
        "id": "amCL0nAgMvF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBOOST REGRESSION**"
      ],
      "metadata": {
        "id": "RlOR0ru4PEIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing XGBRegressor from xgboost\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Create a XGBoost regressor\n",
        "XGBoost_regressor = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
        "\n",
        "# Train the model using the training sets\n",
        "XGBoost_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "0UMijE3vNJ2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "y_pred = XGBoost_regressor.predict(X_test)\n",
        "\n",
        "print('Model Score:',round(r2_score(y_test, y_pred),3))\n",
        "print('Mean Absolute Error:', round(mean_absolute_error(y_test, y_pred),3))\n",
        "print('Mean Squared Error:', round(mean_squared_error(y_test, y_pred),2))\n",
        "print('Root Mean Squared Error:' , round(np.sqrt(mean_squared_error(y_test, y_pred)),2))"
      ],
      "metadata": {
        "id": "ZivkSu8TUcnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rwCrVpKwi8HW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}